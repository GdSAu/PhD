{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación de NBV \n",
    "\n",
    "En este notebook implementaremos un sistema para reconstrucción via NBV haciendo uso de la arquitectura autoencoder y MLP\n",
    "\n",
    "* pedirá la dirección a la carpeta contenedora del objeto\n",
    "* Creará un link simbolico para acceder a las texturas (verifica si no existe ya) y carpetas para almacenar la información obtenida durante el proceso: \n",
    "    - Nubes de puntos\n",
    "    - RGB\n",
    "    - Profundidad\n",
    "* Despliega el objeto para verificar si es el que espera el usuario y debe confirmar si es correcto\n",
    "* Genera una posición y orientación random (podría extraerla de Hintertoiser), importante conocer el bounding box para no colisionar con el objeto\n",
    "* Inicia el proceso de reconstrucción\n",
    "* Captura información y almacena \n",
    "* Crea grid de 31x31x31\n",
    "* Procesamiento de IA\n",
    "* Condición si la cumple repite o finaliza\n",
    "* Reporte de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import open3d as o3d\n",
    "import octomap\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from symlink import symbolic_dir\n",
    "from utils_o3d_v2 import Get_Pointcloud, Get_RGBD, Get_octree, Get_PointcloudGT, scale_and_translate, Get_voxpoints\n",
    "from MLP import MLP\n",
    "from utils import net_position_nbv\n",
    "from dataset_download import download_collection\n",
    "from utils_metrics import chamfer_distance, Get_cloud_distance, getCobertura\n",
    "from utils_save import GuardarDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['60_CONSTRUCTION_SET', 'CHICKEN_NESTING', 'Cole_Hardware_Hammer_Black', 'Curver_Storage_Bin_Black_Small', 'GARDEN_SWING', 'Playmates_Industrial_CoSplinter_Teenage_Mutant_Ninja_Turtle_Action_Figure', 'RedBlack_Nintendo_3DSXL', 'Threshold_Porcelain_Pitcher_White', 'Weisshai_Great_White_Shark', 'Wishbone_Pencil_Case']\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "FEngine (64 bits) created at 0x2dc42580 (threading is enabled)\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "FEngine (64 bits) created at 0x2dc41d30 (threading is enabled)\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "FEngine (64 bits) created at 0x2dc41d30 (threading is enabled)\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "FEngine (64 bits) created at 0x2dc41d30 (threading is enabled)\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "FEngine (64 bits) created at 0x2dc41d30 (threading is enabled)\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "FEngine (64 bits) created at 0x2dc41d30 (threading is enabled)\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "FEngine (64 bits) created at 0x2dc41d30 (threading is enabled)\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "FEngine (64 bits) created at 0x2dc41d30 (threading is enabled)\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "FEngine (64 bits) created at 0x2dc41d30 (threading is enabled)\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "FEngine (64 bits) created at 0x2dc41d30 (threading is enabled)\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n"
     ]
    }
   ],
   "source": [
    "carpeta_iter = \"Voxnet/Itera4/\"\n",
    "direccion = \"/mnt/6C24E28478939C77/Saulo/ProyectoPHD/\"#Direccion a carpeta contenedora\n",
    "objeto = \"objects\"\n",
    "direccion = direccion + objeto + \"/\"\n",
    "metricas = {\"ID\": [],\"id_objeto\": [], \"iteracion_objeto\":[],\"pose_inicial\":[], \"nube_puntos\":[], \"rejilla\":[], \"nbv\":[], \"id_anterior\":[], \"id_siguiente\":[], \"chamfer\":[], \"ganancia_cobertura\":[], \"cobertura\":[]}\n",
    "umbral = 0.0035\n",
    "listado = os.listdir(direccion)\n",
    "print(listado)\n",
    "I = 0\n",
    "for l in range (0, len(listado)):\n",
    "    #carpeta = input(\"A que carpeta quieres acceder?: \") #object folder\n",
    "    dir_carpeta = direccion + listado[l] + \"/\"\n",
    "    if os.path.lexists( dir_carpeta +\"Point_cloud/\"+ carpeta_iter) == False:\n",
    "        #os.mkdir(dir_carpeta +\"Point_cloud/Voxnet/\")\n",
    "        #os.mkdir(dir_carpeta +\"Octree/Voxnet/\")\n",
    "        #os.mkdir(dir_carpeta + \"RGB/Voxnet/\" )\n",
    "        #os.mkdir(dir_carpeta + \"Depth/Voxnet/\")\n",
    "        os.mkdir(dir_carpeta +\"Point_cloud/\"+ carpeta_iter)\n",
    "        os.mkdir(dir_carpeta +\"Octree/\"+ carpeta_iter)\n",
    "        os.mkdir(dir_carpeta + \"RGB/\" + carpeta_iter)\n",
    "        os.mkdir(dir_carpeta + \"Depth/\"+ carpeta_iter)\n",
    "\n",
    "    img_H = 320\n",
    "    img_W = 240\n",
    "    #Cargamos los modelos de predicción de posición\n",
    "    model= MLP().cuda() \n",
    "    path_weights = '/mnt/6C24E28478939C77/Saulo/ProyectoPHD/position/weights_entrenamiento_MLP_xavier_normal_2.pth' ## Modificar direccion de pesos\n",
    "    model.load_state_dict(torch.load(path_weights))\n",
    "    device = torch.cuda.current_device()\n",
    "\n",
    "    #Inicializamos el octomap\n",
    "    resolution = .1 # resolucion del octree\n",
    "    octree = octomap.OcTree(resolution) # inicializamos el octree\n",
    "\n",
    "    #Cargamos malla\n",
    "    mesh = o3d.io.read_triangle_mesh(dir_carpeta + '/meshes/model.obj', True)\n",
    "    material = o3d.visualization.rendering.MaterialRecord() # Create material\n",
    "    material.albedo_img = o3d.io.read_image( dir_carpeta + '/meshes/texture.png') # Add texture\n",
    "    mesh = scale_and_translate(mesh)\n",
    "    #Obtenemos pointcloud GT\n",
    "    Get_PointcloudGT(dir_carpeta, mesh, carpeta_iter)\n",
    "\n",
    "    # Raycasting\n",
    "    mesh1 = o3d.t.geometry.TriangleMesh.from_legacy(mesh)\n",
    "    scene = o3d.t.geometry.RaycastingScene()\n",
    "    scene.add_triangles(mesh1)\n",
    "    # render for RGBD images\n",
    "    render = o3d.visualization.rendering.OffscreenRenderer(width=img_W, height=img_H) #Linux only\n",
    "    render.scene.add_geometry('mesh', mesh, material)\n",
    "    #Camera vectors setup\n",
    "    cent = mesh.get_center()\n",
    "    up = [0, 1, 0]\n",
    "    poses = np.load(\"poses.npy\")\n",
    "    eye_init = poses[116]\n",
    "    eye = eye_init\n",
    "    fov = 45\n",
    "    puntos = Get_voxpoints()\n",
    "\n",
    "    \n",
    "    \n",
    "    #print(\"Inicia el proceso de reconstrucción ...\")\n",
    "    #while condicion == False:\n",
    "    for i in range(0,15):    \n",
    "        # RGBD and pointcloud extraction\n",
    "        Get_Pointcloud(scene, fov, cent, eye, up, img_W, img_H, dir_carpeta, i, carpeta_iter, save_acc= True)\n",
    "        Get_RGBD(render,  fov, cent, eye, up, dir_carpeta, i, carpeta_iter)\n",
    "        #Occupancy grid\n",
    "        occupancy_probs =  Get_octree(octree, dir_carpeta, i, carpeta_iter, eye, puntos)\n",
    "        ## Aqui evaluamos si esta completo el modelo en este punto\n",
    "        CD = chamfer_distance(dir_carpeta, carpeta_iter)\n",
    "        condicion, coverage_gain = Get_cloud_distance(dir_carpeta, i, carpeta_iter)\n",
    "        cov = getCobertura(dir_carpeta, carpeta_iter, i, umbral=umbral)\n",
    "        #print(\"Chamfer Distance: {}, Cloud distances: {}, # view: {}\".format(CD, Distance, i))\n",
    "        if condicion == True:\n",
    "            GuardarDS(metricas,I, i, listado[l], eye_init, eye, octree, occupancy_probs, dir_carpeta, carpeta_iter, CD, coverage_gain, cov)\n",
    "            break\n",
    "        ## De no estarlo, se consulta a la NN el NBV \n",
    "        else:\n",
    "            grid = np.reshape(occupancy_probs, (1,1,31,31,31))  \n",
    "            torch_grid = torch.from_numpy(grid)\n",
    "            #IA-NBV\n",
    "            output = net_position_nbv(model, torch_grid, device) \n",
    "            eye = output.numpy().reshape(3,).astype(\"double\")\n",
    "            GuardarDS(metricas,I, i, listado[l], eye_init, eye, octree, occupancy_probs, dir_carpeta, carpeta_iter, CD, coverage_gain,cov) \n",
    "        #print(\"nbv:\", eye)\n",
    "        I += 1\n",
    "    del octree\n",
    "    del mesh\n",
    "    del mesh1\n",
    "    del material\n",
    "    del scene\n",
    "    del render\n",
    "\n",
    "#print(metricas)   \n",
    "#print(\"Volví, tonotos!\")\n",
    "#almacena las métricas de error en archivo NPZ\n",
    "dataframe = pd.DataFrame(metricas, index=None)\n",
    "dataframe.to_csv('NBV_Voxnet5.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cobertura por objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cobertura del objeto: 60_CONSTRUCTION_SET es: 66.22162207781247%\n",
      "La cobertura del objeto: CHICKEN_NESTING es: 44.8002127013066%\n",
      "La cobertura del objeto: Cole_Hardware_Hammer_Black es: 54.19357971929484%\n",
      "La cobertura del objeto: Curver_Storage_Bin_Black_Small es: 50.48726497846114%\n",
      "La cobertura del objeto: GARDEN_SWING es: 67.46942615239887%\n",
      "La cobertura del objeto: Playmates_Industrial_CoSplinter_Teenage_Mutant_Ninja_Turtle_Action_Figure es: 66.18707617236555%\n",
      "La cobertura del objeto: RedBlack_Nintendo_3DSXL es: 88.68709677419355%\n",
      "La cobertura del objeto: Threshold_Porcelain_Pitcher_White es: 49.03378551318147%\n",
      "La cobertura del objeto: Weisshai_Great_White_Shark es: 55.28559935639582%\n",
      "La cobertura del objeto: Wishbone_Pencil_Case es: 69.52674444199867%\n",
      "Tenemos una media de: 61.18924078874089, un máximo de 88.68709677419355 y mínimo de 44.8002127013066, con un promedio de 3 nuevas vistas por objeto\n"
     ]
    }
   ],
   "source": [
    "carpeta_iter = \"Voxnet/Itera5/\"\n",
    "direccion = \"/mnt/6C24E28478939C77/Saulo/ProyectoPHD/\"#Direccion a carpeta contenedora\n",
    "objeto = \"objects\"\n",
    "direccion = direccion + objeto + \"/\"\n",
    "listado = os.listdir(direccion)\n",
    "umbral = 0.0035\n",
    "cov = []\n",
    "for l in range (0,len(listado)):\n",
    "    dir_carpeta = direccion + listado[l] + \"/\"\n",
    "    cov.append(getCobertura(dir_carpeta,carpeta_iter,i=1,umbral=umbral))\n",
    "    print(\"La cobertura del objeto: {} es: {}%\".format(listado[l],cov[l]))\n",
    "cov_arrays = np.asarray(cov)\n",
    "print(\"Tenemos una media de: {}, un máximo de {} y mínimo de {}, con un promedio de 3 nuevas vistas por objeto\".format(cov_arrays.mean(), cov_arrays.max(), cov_arrays.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualización de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteo nube acumulada\n",
    "\n",
    "gt = direccion + listado[1] + \"/Point_cloud/\" + carpeta_iter + \"cloud_acc.pcd\"\n",
    "nube_puntos = o3d.io.read_point_cloud(gt)\n",
    "o3d.visualization.draw_geometries([nube_puntos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "o3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
